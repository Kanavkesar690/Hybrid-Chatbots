from langchain.tools import BaseTool
from ..callbacks.sql_streaming import SQLHandler
from typing import Optional, Any, Dict
from langchain.callbacks.manager import CallbackManagerForToolRun, AsyncCallbackManagerForToolRun
from langchain.prompts.few_shot import FewShotPromptTemplate
from langchain_core.prompts import FewShotChatMessagePromptTemplate, ChatPromptTemplate
from langchain.agents import AgentExecutor
import re
from HybridFunction.Hybrid_Main import sql_tool_desc

# Custom tool to execute natural language to SQL workflows using LangChain and a SQL Agent
class SQLServerDBTool(BaseTool):
    # Annotate these as str so pydantic (BaseTool) treats them as proper fields
    name: str = "SQLServerDBTool"
    description: str = f"{sql_tool_desc} Always pass a natural language question in English in the query parameter to process."

    handler: Optional[SQLHandler] = None
    sql_agent: Optional[AgentExecutor] = None
    model: Optional[str] = None

    async def _arun(self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:
        """Synchronous query handling."""
        try:
            # Step 1: Build a few-shot or chat-based prompt depending on model type
            from HybridFunction.Hybrid_Main import create_prompt, examples, task_description, db, llm, insert_exception_log
            example_prompt = create_prompt(query, self.model.lower())
            prompt = self._create_prompt(query, example_prompt, examples, task_description)

            # Step 2: Run the SQL agent to generate and execute SQL, attach callback handler
            try:
                response = self.sql_agent.invoke(prompt, {"callbacks": [self.handler]})
            except Exception as e:
                return self._handle_exception(e)

            # Step 3: Extract the SQL query from callback handler
            sql_query = self._extract_sql_query()
            if not sql_query:
                return self._generate_error_response("Failed to generate SQL query.")

            # Step 4: Clean query (remove TOP N limits if present) and run against DB
            cleaned_query = re.sub(r'top\s+\d+', '', sql_query, flags=re.IGNORECASE)
            result_excel = db._execute(cleaned_query)

            if not result_excel:
                return self._generate_error_response("No Data Found based on your criteria.", sql_query)

            # Step 5: Return formatted NLP response
            return response.get('output')

        except Exception as e:
            return self._handle_exception(e)


    def _run(self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None) -> str:
        """Processes a natural language query, generates the SQL query, executes it, and returns results in NLP format."""
        pass
    # Helper to create the prompt based on the model.
    # This allows for different prompt structures based on the model type (e.g., GPT-4, GPT-4o)
    def _create_prompt(self, query: str, example_prompt: Any, examples: Any, task_description: Any) -> Any:
        """Helper to create the prompt based on the model."""
        if self.model.lower() in ['gpt4', 'gpt-4', 'gpt_4']:
            return FewShotPromptTemplate(
                examples=examples,
                example_prompt=example_prompt,
                suffix=f"Question: {query}",
                input_variables=["input"]
            )
        elif self.model.lower() in ['gpt-5-mini', 'gpt5-mini', 'gpt-5mini','gpt_5_mini', 'gpt-5', 'gpt5', 'gpt_5']:
        # elif self.model.lower() in ['gpt-4o', 'gpt4o', 'gpt_4o']:
            return ChatPromptTemplate.from_messages([
                ("system", task_description),
                FewShotChatMessagePromptTemplate(examples=examples, example_prompt=example_prompt),
                ("human", "{input}")
            ]).format_messages(input=query)

    # Helper to extract the SQL query from the handler.
    # This is used to retrieve the SQL query generated by the agent.
    def _extract_sql_query(self) -> Optional[str]:
        """Helper to extract SQL query from the handler."""
        if hasattr(self.handler, 'sql_result'):
            if isinstance(self.handler.sql_result, str):
                return self.handler.sql_result
            if isinstance(self.handler.sql_result, dict) and 'query' in self.handler.sql_result:
                return self.handler.sql_result['query']
        return None

    # Helper to handle exceptions including context length and SQL issues.
    # This is used to log exceptions and return appropriate error messages.
    def _handle_exception(self, e: Exception) -> str:
        """Handle exceptions including context length and SQL issues."""
        from HybridFunction.Hybrid_Main import db, llm, insert_exception_log

        sql_query = self._extract_sql_query()
        if hasattr(e, 'code') and e.code in ['context_length_exceeded', 'string_above_max_length']:
            if sql_query:
                result = db._execute(sql_query)
                if not result:
                    return self._generate_error_response('Please provide more details and try again later.')

                dataset_snippet = result[:15]
                prompt_text = (
                    f"Given the dataset snippet '{dataset_snippet}' generated using the query '{sql_query}', "
                    f"corresponding to the question '{sql_query}', generate an NLP response in a structured format with "
                    f"headings and subheadings. Create a chatbot-like response without mentioning 'The dataset provided information'."
                )
                res = llm.invoke(prompt_text)
                return res.content

        return self._generate_error_response('Please provide more details and try again later', sql_query)

    # Helper to generate error response 
    def _generate_error_response(self, message: str, query: Optional[str] = None) -> str:
        """Helper to generate error response."""
        return message

